{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install --upgrade pip\n",
    "# ! pip3 install pkg_resouces\n",
    "# ! pip3 install openpyxl\n",
    "# ! pip3 install pandas\n",
    "# ! pip3 install scipy\n",
    "\n",
    "import pip\n",
    "import pkg_resources\n",
    "import os\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "from matplotlib.colors import ListedColormap \n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## フォルダ関係"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip関係, フォルダ関係\n",
    "def pip_check(pip_name):        #pipでライブラリをインストールする関数\n",
    "    list_ = [_lib.project_name for _lib in pkg_resources.working_set]\n",
    "    if pip_name not in list_:\n",
    "        pip.main(['install', '--upgrade', 'pip'])\n",
    "        pip.main(['install', pip_name])\n",
    "        print('Installed: ' + pip_name)\n",
    "    else:\n",
    "        print('Already installed: ' + pip_name)\n",
    "\n",
    "def check_dir(fig_dir):     #フォルダの有無を確認なければ作る\n",
    "    try:\n",
    "        os.makedirs(fig_dir)\n",
    "    except FileExistsError:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## openpyexel関係"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_list_xlsx_sheet(sheet, input_list, start_row = 1, start_col = 1):     #リストをエクセルに書き込む関数 \n",
    "    for y, row_data in enumerate(input_list):\n",
    "        for x, cell_data in enumerate(row_data):\n",
    "            sheet.cell(row=start_row + y, column = start_col + x, value = input_list[y][x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 検定関係"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def facter_binarization(df, facter_th = ['HbA1c', '>= 5.6']):        #カテゴリー変数を２値化、trueが１、true_valueはリスト\n",
    "    df[f'{facter_th[0]}_'] = list(eval(f\"(df['{facter_th[0]}']\\\n",
    "                                       .mask(df['{facter_th[0]}'] {facter_th[1]}, 1)\\\n",
    "                                       .mask(~(df['{facter_th[0]}'] {facter_th[1]}), 0)\\\n",
    "                                       .mask(df['{facter_th[0]}'].isnull(), np.nan))\"\n",
    "                                       ))\n",
    "\n",
    "def average_delta_check_for_binary_data(df, decimal_point = 3): #０、１カラムを検定\n",
    "    column_names = df.columns.to_list()\n",
    "    for column_name in column_names:\n",
    "        if df[column_name].unique() == [0, 1]:\n",
    "            average_delta_check(column_name, df, decimal_point, save_xlsx_name = f'{column_name}検定結果')\n",
    "\n",
    "def average_delta_check(aim_facter, df, decimal_point = 3, save_xlsx_name = '検定結果'):  #平均値の差があるかどうか\n",
    "    column_names = df.columns.to_list()\n",
    "    data_size = len(df)     ####   \n",
    "    df_hit = df[df[aim_facter] == 1]    #異常あり\n",
    "    df_miss = df[df[aim_facter] == 0]   #異常なし\n",
    "    df_lists = [['column_name', 'method', 'hit_p', 'miss_p', 'method_t', 'ttest_p']]\n",
    "    for column_name in column_names:\n",
    "        if df[column_name].dtypes == 'float':\n",
    "            if len(df[column_name].unique()) < 5:\n",
    "                continue\n",
    "        else:\n",
    "            continue\n",
    "        if data_size > 1000:\n",
    "            method = 'ks'\n",
    "            hit_ks_p = round(stats.kstest(df_hit[column_name], 'norm')[1], decimal_point)\n",
    "            miss_ks_p = round(stats.kstest(df_miss[column_name], 'norm')[1], decimal_point)\n",
    "            if hit_ks_p > 0.05 or miss_ks_p > 0.05:\n",
    "                result = 'not_normal'\n",
    "            else:\n",
    "                result = 'normal'\n",
    "        else:\n",
    "            method = 'shapiro'\n",
    "            hit_shapiro_p = round(stats.shapiro(df_hit[column_name])[1], decimal_point)\n",
    "            miss_shapiro_p = round(stats.shapiro(df_miss[column_name])[1], decimal_point)\n",
    "            if hit_shapiro_p > 0.05 or miss_shapiro_p > 0.05:\n",
    "                result = 'not_normal'\n",
    "            else:\n",
    "                result = 'normal'\n",
    "        if result == 'not_normal':      #正規分布でない場合\n",
    "            mannwhitneyu_p = round(stats.mannwhitneyu(df_hit[column_name], df_miss[column_name])[1], decimal_point)\n",
    "            df_lists.append([column_name, method, eval(r'hit_{0}_p'.format(method)), eval(r'miss_{0}_p'.format(method)), 'Man_U', mannwhitneyu_p])\n",
    "        elif result == 'normal':        #正規分布の場合\n",
    "            f_p = stats.f_oneway(df_hit[column_name], df_miss[column_name])[1]      #F検定、0.05以上ならば等分散\n",
    "            if f_p < 0.05:\n",
    "                method_t = 'welch'\n",
    "                ttest_p = round(stats.ttest_ind(df_hit[column_name], df_miss[column_name], equal_var = False)[1], decimal_point)      #等分散でない場合、ウェルチのt検定\n",
    "            else :\n",
    "                method_t = 'student'\n",
    "                ttest_p = round(stats.ttest_ind(df_hit[column_name], df_miss[column_name], equal_var = True)[1], decimal_point)       #等分散の場合、スチューデントのt検定 \n",
    "            df_lists.append([column_name, method,  eval(r'hit_{0}_p'.format(method)), eval(r'miss_{0}_p'.format(method)), method_t, ttest_p])\n",
    "    #一枚エクセルに書き込み\n",
    "    # save_df = pd.DataFrame(df_lists, columns = ['column_name', 'method', 'hit_p', 'miss_p', 'method_t', 'ttest_p'])\n",
    "    # with pd.ExcelWriter('検定結果.xlsx') as writer:\n",
    "    #     save_df.to_excel(writer, sheet_name = '検定結果')\n",
    "\n",
    "    #excelに書き込み\n",
    "    book = openpyxl.Workbook()\n",
    "    sheet = book['Sheet']\n",
    "    sheet.title = '検定結果'\n",
    "    write_list_xlsx_sheet(sheet, df_lists)\n",
    "    book.save(f'{save_xlsx_name}.xlsx')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保険データに対して"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colors_scale(legend_unique, cmap_name = 'bwr_r', division_number = 5):                  #色の分け方の定義\n",
    "    n_min = 1  #min(arr)\n",
    "    n_max = division_number   #max(arr)\n",
    "    cmap = plt.colormaps[cmap_name]\n",
    "    norm = matplotlib.colors.Normalize(vmin=n_min, vmax=n_max)\n",
    "    arr = [cmap(norm(r)) for r in legend_unique]\n",
    "    return arr, cmap, norm\n",
    "\n",
    "def plot_map_colors(df, facter_column = '区分'):                                            # マップの作製\n",
    "    legend_unique = sorted(df[facter_column].unique().tolist())\n",
    "    labels = {1: '有意に高い', 2: '有意で無いが高い', 3: 'なし' ,4: '有意で無いが低い', 5: '有意に低い'}\n",
    "    ratio_legend = [labels[a] for a in legend_unique]\n",
    "    target_colors, cmap, norm = colors_scale(legend_unique)\n",
    "    cmaps = ListedColormap(target_colors, name=\"custom\")\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.axis('off')                      # 軸を表示しない\n",
    "    df.plot(\n",
    "        ax = ax, \n",
    "        column = facter_column, \n",
    "        categorical = True,\n",
    "        cmap = cmaps,\n",
    "        edgecolor = '#000000', \n",
    "        linewidth = 1, \n",
    "        legend = True, \n",
    "        legend_kwds={'labels': ratio_legend}\n",
    "        )\n",
    "\n",
    "    # #ラベルを付ける\n",
    "    # for i, txt in enumerate(df['市町村名']):\n",
    "    #     ax.annotate(txt, (df.geometry[i].centroid.x, df.geometry[i].centroid.y),fontsize= 6,horizontalalignment='center', verticalalignment='center')\n",
    "    # fig.text(0.5, 0.1, '※本資料を活用するには、必ず、各市町村の表も合わせて解釈を行うこと。', ha='center',fontsize= 10, horizontalalignment=\"center\",verticalalignment=\"center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# メモ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## カラーコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmaps = ListedColormap(target_colors, name=\"custom\")\n",
    "# target_colorsにカラーコードのリストを渡すことで離散的なカラーマップを作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target.drop(columns = df_target.columns[~df_target.columns.str.endswith((f'{target_years[0]}','判定'))], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "endswith\n",
    "- 第一引数に()タプルを渡すことで複数の条件を指定することができる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 標準コード\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'\\u3000'\n",
    "# 全角スペース"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
