{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 色々"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "メタボの分類\n",
    "データ変換\n",
    "回帰\n",
    "スコアの評価\n",
    "データ化\n",
    "\n",
    "関数化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install patsy\n",
    "# ! pip3 install statsmodels\n",
    "# ! pip3 install --upgrade pip\n",
    "# ! pip3 install pandas\n",
    "#import, def, path\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def make_pair(target_list, span):#リストから指定の間隔をあけて二つを取り出す\n",
    "    pairs = [[target_list[i], target_list[i + span]] for i in range(len(target_list) - span)]\n",
    "    return pairs\n",
    "def marge_columns(df, columns):#カラムを追加する\n",
    "    mid = pd.DataFrame(index=df.index, columns=columns)\n",
    "    return pd.concat([df, mid], axis=1)\n",
    "def check_metS(df, metS_facter):#メタボ因子を数値化\n",
    "    metS_keys = list(metS_facter.keys())\n",
    "    metS_values = list(metS_facter.values())\n",
    "    df['check_腹囲'] = list(eval(f\"df['{metS_keys[0]}'] {metS_values[0]}\"))\n",
    "    df['check_血圧'] = list(eval(f\"df['{metS_keys[1]}'] {metS_values[1]}\"))\n",
    "    df['check_血糖'] = list(eval(f\"df['{metS_keys[2]}'] {metS_values[2]}\"))\n",
    "    df['check_脂肪'] = list(eval(f\"df['{metS_keys[3]}'] {metS_values[3]}\"))\n",
    "    return df\n",
    "def categorize_facters(df, categorize_facter = [['性別', '== 1']]):# カテゴリー変数を２値化、trueが１、true_valueはリスト\n",
    "    facters = list(categorize_facter.keys())\n",
    "    true_values = list(categorize_facter.values())\n",
    "    for i, true_value in enumerate(true_values):\n",
    "        k += f\"df['{facters[i]}'] == {true_value} |\"\n",
    "    df[f'categorize_{facters[i]}'] = list(eval(k[: -1]))\n",
    "    return df\n",
    "# facter_binarization\n",
    "def facter_binarization(df, facter_th = ['HbA1c', '>= 5.6']):        #カテゴリー変数を２値化、trueが１、true_valueはリスト\n",
    "    df[f'{facter_th[0]}_'] = list(eval(f\"(df['{facter_th[0]}']\\\n",
    "                                       .mask(df['{facter_th[0]}'] {facter_th[1]}, 1)\\\n",
    "                                       .mask(~(df['{facter_th[0]}'] {facter_th[1]}), 0)\\\n",
    "                                       .mask(df['{facter_th[0]}'].isnull(), np.nan))\"\n",
    "                                       ))\n",
    "\n",
    "df_name = pd.read_csv('/Volumes/USBDISK/AHHDC/sort_pg/練習用保健データ.csv',  encoding = 'cp932')\n",
    "#main_df_path = os.path.join(os.getcwd(), f'{df_name}.csv')\n",
    "target_list = list(range(2015, 2021))\n",
    "span = 4\n",
    "pairs_column = '検診実施年度'\n",
    "metS_facter = {'腹囲':'>= 85', '血圧':'>= 130', '血糖':'>= 110', '脂肪':'>= 150'}\n",
    "metS_keys = list(metS_facter.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_name.copy()\n",
    "#df = df['空腹時血糖']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df = df_name.copy()\n",
    "metS_facter = [\n",
    "    ['性別', '腹囲'],               # 腹囲\n",
    "    ['収縮機血圧', '拡張期血圧'],     # 血圧\n",
    "    ['空腹時血糖', 'HbA1c'],        # 血糖\n",
    "    ['中性脂肪', 'HDL']             # 脂質\n",
    "]\n",
    "\n",
    "df['腹囲_'] = (((df[metS_facter[0][0]] == 1) & (df[metS_facter[0][1]] >= 85) |   # 男性\n",
    "              (df[metS_facter[0][0]] == 0) & (df[metS_facter[0][1]] >= 90))     # 女性\n",
    "               .where((df[metS_facter[0][0]].notnull()) & (df[metS_facter[0][1]].notnull()), np.nan)) \n",
    "df['血圧_'] = (((df[metS_facter[1][0]] >= 130) |    # 収縮期血圧\n",
    "              (df[metS_facter[1][1]] >= 85))       # 拡張期血圧\n",
    "               .where((df[metS_facter[1][0]].notnull()) & (df[metS_facter[1][1]].notnull()), np.nan))\n",
    "df['血糖_'] = (((df[metS_facter[2][0]] >= 110) |    # 空腹時血糖\n",
    "              (df[metS_facter[2][1]] >= 5.6))             # HbA1c\n",
    "               .where((df[metS_facter[2][0]].notnull()) & (df[metS_facter[2][1]].notnull()), np.nan))\n",
    "df['脂質_'] = (((df[metS_facter[3][0]] >= 150) |    # 中性脂肪\n",
    "              (df['HDL'] <= 40))               # HDL\n",
    "               .where((df[metS_facter[3][0]].notnull()) & (df[metS_facter[3][1]].notnull()), np.nan))\n",
    "# nanの変換\n",
    "# df['腹囲'] = df['腹囲'].where((~df['腹囲'].notnull()) | (~df['性別'].notnull()), np.nan)\n",
    "# df['血圧'] = df['血圧'].where((~df['収縮機血圧'].notnull()) | (~df['拡張期血圧'].notnull()), np.nan)\n",
    "# df['血糖'] = df['血糖'].where((~df['空腹時血糖'].notnull()) | (~df['HbA1c'].notnull()), np.nan)\n",
    "# df['脂質'] = df['脂質'].where((~df['中性脂肪'].notnull()) | (~df['HDL'].notnull()), np.nan)\n",
    "\n",
    "# 判定\n",
    "df['MetS'] = (df['腹囲_'] == True) & ((df['血圧_'] + df['血糖_'] + df['脂質_'] >= 2))\n",
    "\n",
    "df_metS = df[df['MetS'] == True]\n",
    "df_non_metS = df[df['MetS'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facter = 'HbA1c' \n",
    "true_value = '>= 5.6'\n",
    "import numpy as np\n",
    "df[f'{facter}_'] = list(eval(f\"df['{facter}'].mask(df['{facter}'] {true_value}, 1)\\\n",
    "                             .mask(~(df['{facter}'] {true_value}), 0)\\\n",
    "                             .mask(df['{facter}'].isnull(), np.nan)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facter_binarization(df, facter_th = ['空腹時血糖', '>= 110'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 糖尿病診断\n",
    "df = df_name.copy()\n",
    "facter_binarization(df, facter_th = ['空腹時血糖', '>= 110'])\n",
    "facter_binarization(df, facter_th = ['HbA1c', '>= 6.5'])\n",
    "\n",
    "# 糖尿病の判定\n",
    "\n",
    "df['糖尿病'] = (df['空腹時血糖_'].mask((df['空腹時血糖_'] == True) | (df['HbA1c_'] == True), 's/o')\n",
    "                              .mask((df['空腹時血糖_'] == True) & (df['HbA1c_'] == True), True)\n",
    "                              .mask((df['空腹時血糖_'] == False), False)\n",
    "                              .mask((df['空腹時血糖_'].isnull()), np.nan)\n",
    "                              )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main\n",
    "df = df_name\n",
    "id_column = 'Unnamed: 0'\n",
    "categorize_facter = {'namae':[1,2]}\n",
    "\n",
    "pairs = make_pair(target_list, span, id_column, categorize_facter)\n",
    "for pair in pairs:\n",
    "    df1 = df.query(f'{pairs_column} == {pair[0]}')#train\n",
    "    df1 = check_metS(df1, metS_facter)\n",
    "    df1 = categorize_facters(df1, categorize_facter)\n",
    "    df2 = df.query(f'{pairs_column} == {pair[1]}')#test\n",
    "    df2 = check_metS(df2, metS_facter)\n",
    "    df2 = df2.filter(regex = f'^({id_column}| check_)', axis = 1)#testは必要のないもの以外drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_name\n",
    "#df = marge_columns(df, ['check_腹囲', 'check_血圧', 'check_血糖', 'check_脂肪'])\n",
    "metS_values = list(metS_facter.values())\n",
    "a = '検診実施年度'\n",
    "true_value = [2018, 2019]\n",
    "k = ''\n",
    "for i in true_value:\n",
    "    k += f\"(df['{a}'] == {i}) |\"\n",
    "\n",
    "df[f'check_{a}'] = list(eval(k[:-1]))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "各群にrisk_facter_name\n",
    "\n",
    "比べてchange\n",
    "変化した：１\n",
    "変化なし：０\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_name = '睡眠時間'\n",
    "\n",
    "\n",
    "X = df[[column_name]] # 説明変数\n",
    "Y = df['species'].map({'versicolor': 0, 'virginica': 1}) # versicolorをクラス0, virginicaをクラス1とする\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0) # 80%のデータを学習データに、20%を検証データにする\n",
    "\n",
    "lr = LogisticRegression() # ロジスティック回帰モデルのインスタンスを作成\n",
    "lr.fit(X_train, Y_train) # ロジスティック回帰モデルの重みを学習\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#main\n",
    "\n",
    "df = pd.read_csv(main_df_path)\n",
    "id_column = 'Unnamed: 0'\n",
    "categorize_facter = {'namae':[1,2]}\n",
    "facter_bp = '血圧'\n",
    "bp_threshold = '>= 135'\n",
    "columns_list = list(df.columns)\n",
    "pairs = make_pair(target_list, span, id_column, categorize_facter)\n",
    "for pair in pairs:\n",
    "    df1 = df.query(f'{pairs_column} == {pair[0]}')#train\n",
    "    df1['check_高血圧'] = list(eval(f\"df1['{facter_bp}'] {bp_threshold}\"))\n",
    "    df1 = df1[df1['check_高血圧'] == False]     #元々正常のみ\n",
    "\n",
    "    df2 = df.query(f'{pairs_column} == {pair[1]}')#test\n",
    "    df1['check_高血圧_after'] = list(eval(f\"df2['{facter_bp}'] {bp_threshold}\"))\n",
    "    df2 = df2.filter(regex = f'^({id_column}| check_)', axis = 1)#testは必要のないもの以外drop\n",
    "\n",
    "    df1.join(df2, on = id_column)\n",
    "    df1.dropna(subset=['check_高血圧_after'], inplace = True)\n",
    "    df1['bp_delta'] = df1['check_高血圧_after'] - df1['check_高血圧']\n",
    "\n",
    "    x = df1[['name']] # 説明変数\n",
    "    y = df1['bp_delta'].map({0: 0, 1: 1}) # falseをクラス0, Trueをクラス1とする\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size = 0.2, random_state = 0) # 80%のデータを学習データに、20%を検証データにする\n",
    "\n",
    "\n",
    "    lr = LogisticRegression() # ロジスティック回帰モデルのインスタンスを作成\n",
    "    lr.fit(X_train, Y_train) # ロジスティック回帰モデルの重みを学習\n",
    "\n",
    "\n",
    "    df_model[\"偏回帰係数\"] = model.coef_[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# データの読み込み\n",
    "exam_data = pd.read_csv(\"exam_data.csv\")\n",
    "# データのグラフ化\n",
    "\n",
    "\n",
    "# モデル化\n",
    "logistic_model = smf.glm(formula = \"result ~ hours\", # 目的変数~説明変数\n",
    "                       data = exam_data, \n",
    "                       family=sm.families.Binomial(link=sm.genmod.families.links.logit())\n",
    "                        )\n",
    "\n",
    "logistic_result = logistic_model.fit()\n",
    "\n",
    "logistic_result.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X2乗検定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "chi2, p, dof, exp = stats.chi2_contingency(df_name['検診実施年度','市町村名'], correction=False) #correction:イェーツの補正\n",
    "print(\"期待度数\", \"\\n\", exp)\n",
    "print(\"自由度\", \"\\n\", dof)\n",
    "print(\"カイ二乗値\", \"\\n\", chi2)\n",
    "print(\"p値\", \"\\n\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "def chi_squeretest(df, facters_list = []):\n",
    "    facters_pairs = [[facters_pair] for facters_pair in combinations(facters_list, 2)]\n",
    "    separate_facter = []\n",
    "    for facters_pair in facters_pairs:\n",
    "        chi2, p, dof, exp = stats.chi2_contingency(df[facters_pair], correction=False) #correction:イェーツの補正\n",
    "        if p < 0.05 :\n",
    "            separate_facter.append(facters_pair)\n",
    "    return separate_facter#[[a,a],[b,b]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "facters_list = ['検診実施年度', '市町村名']\n",
    "categorize_threshhold = 3\n",
    "df = df_name\n",
    "#X2検定\n",
    "from itertools import combinations\n",
    "def chi_squeretest(df, categorize_threshhold = 3, facters_list = []):\n",
    "    categorize_facters_list = [facter for facter in facters_list if len(df[facter].unique()) < categorize_threshhold]\n",
    "    facters_pairs = [facters_pair for facters_pair in combinations(categorize_facters_list, 2)]\n",
    "    separate_facter = []\n",
    "    print(facters_pairs)\n",
    "    for facters_pair in facters_pairs:\n",
    "        cross_tab = pd.crosstab(df[facters_pair[0]], df[facters_pair[1]])\n",
    "        print(cross_tab)\n",
    "        p = stats.chi2_contingency(cross_tab, correction=False)[1] #correction:イェーツの補正\n",
    "        print(p)\n",
    "        if p < 0.05 :\n",
    "            separate_facter.append(facters_pair)\n",
    "    return separate_facter#[[a,a],[b,b]]\n",
    "\n",
    "\n",
    "def fisher_exact_test(df, categorize_threshhold = 3, facters_list = []):\n",
    "    categorize_facters_list = [facter for facter in facters_list if len(df[facter].unique()) < categorize_threshhold]\n",
    "    facters_pairs = [facters_pair for facters_pair in combinations(categorize_facters_list, 2)]\n",
    "    separate_facter = []\n",
    "    for facters_pair in facters_pairs:\n",
    "        cross_tab = pd.crosstab(df[facters_pair[0]], df[facters_pair[1]])\n",
    "        p = stats.fisher_exact(cross_tab)[1] #correction:イェーツの補正\n",
    "        if p < 0.05 :\n",
    "            separate_facter.append(facters_pair)\n",
    "    return separate_facter#[[a,a],[b,b]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_tab = pd.crosstab(df[facters_list[0]], df[facters_list[1]])\n",
    "cross_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_sums = cross_tab.sum().to_list()        #c   \n",
    "row_sums = cross_tab.sum(axis = 1).to_list()   #r\n",
    "full_sum = sum(column_sums)                    #n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import itertools\n",
    "def list_factorial_sum(taraget_list):\n",
    "    sum = 0\n",
    "    for target in taraget_list:\n",
    "        m = math.factorial(target)\n",
    "        sum += m\n",
    "    return sum\n",
    "\n",
    "\n",
    "column_factorial = 0\n",
    "for column_sum in column_sums:\n",
    "    m = math.factorial(column_sum)\n",
    "    column_factorial += m\n",
    "\n",
    "row_factorial = 0\n",
    "for row_sum in row_sums:\n",
    "    m = math.factorial(row_sum)\n",
    "    row_factorial += m\n",
    "\n",
    "n_factorial = math.factorial(full_sum)\n",
    "\n",
    "values_factorial = 0\n",
    "cross_tab_values = list(itertools.chain.from_iterable(cross_tab.values.tolist()))\n",
    "for cross_tab_value in cross_tab_values:\n",
    "    m = math.factorial(cross_tab_value)\n",
    "    values_factorial += m\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_tab_values = cross_tab.values.tolist()\n",
    "for cross_tab_value in cross_tab_values:    #行ごと\n",
    "    rows_value_factorial_sum = 0\n",
    "    for i, cross_tab_value in enumerate(cross_tab_values):\n",
    "        row_value_factorial_sum = list_factorial_sum(cross_tab_value)\n",
    "        row_factorial = math.factorial(column_sums[i])\n",
    "        k = row_value_factorial_sum/row_factorial\n",
    "        rows_value_factorial_sum += k\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_value_factorial_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_p = n_factorial/column_factorial\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_p = n_factorial/column_factorial\n",
    "p\n",
    "rows_value_factorial_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_tab_values = cross_tab.values.tolist()\n",
    "for cross_tab_value in cross_tab_values:    #行ごと\n",
    "    rows_value_factorial_sum = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 綺麗なエクセルを整形する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "\n",
    "book = openpyxl.Workbook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['haba'] = f\"{df['random_num1']}\" + f\"{df['random_num2']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 地図"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ミス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip3 install folium\n",
    "import folium\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 市町村の境界データの読み込み\n",
    "f = open('/Volumes/USBDISK/AHHDC/オープンデータ/群馬県行政区域/N03-23_10_230101.geojson', 'r', encoding='utf-8_sig')\n",
    "geojson = json.load(f)\n",
    "f.close()\n",
    "\n",
    "# マップの作製\n",
    "map_center = [43.06417, 141.34694] #札幌\n",
    "m1 = folium.Map(location=map_center, tiles='cartodbpositron', zoom_start=7)\n",
    "folium.Choropleth(\n",
    "    geo_data=geojson,\n",
    ").add_to(m1)\n",
    "folium.LayerControl().add_to(m1)\n",
    "m1.save('hokkaido.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip3 install geopandas\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "# Shapefileを読み込む\n",
    "fp = \"/Volumes/USBDISK/AHHDC/オープンデータ/群馬県行政区域/N03-23_10_230101.shp\"\n",
    "gunma = gpd.read_file(fp, encoding=\"cp932\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.axis('off')                      # 軸を表示しない\n",
    "ax.set_aspect('equal', 'datalim')   # 縦横比を揃える\n",
    "gunma.plot(ax = ax, edgecolor = 'black', facecolor = 'aliceblue', linewidth = 0.5)  # 市町村境界を描画\n",
    "plt.title('群馬県')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "#! pip3 install geopandas\n",
    "#! pip3 install mapclassify\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "import mapclassify\n",
    "\n",
    "# Shapefileを読み込む\n",
    "fp = \"/Volumes/USBDISK/AHHDC/オープンデータ/N03-20200101_10_GML/N03-20_10_200101.shp\"\n",
    "#https://nlftp.mlit.go.jp/ksj/gml/datalist/KsjTmplt-N03-v2_4.html\n",
    "gunma = gpd.read_file(fp, encoding=\"cp932\")\n",
    "gunma.rename(columns={'N03_004': '市町村名'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 市町村別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改修前\n",
    "import random\n",
    "import pandas as pd\n",
    "from matplotlib.colors import ListedColormap            ##########\n",
    "\n",
    "# テスト用のデータを作成\n",
    "municipalities = gunma['市町村名'].unique().tolist()\n",
    "lists = [random.choice([1, 2, 3, 4]) for i in range(len(gunma['市町村名'].unique()))]\n",
    "df_municipalities = pd.DataFrame({'市町村名': municipalities,\n",
    "                                  '該当比': lists})\n",
    "gunma = pd.merge(gunma, df_municipalities, on = '市町村名')\n",
    "\n",
    "\n",
    "#########\n",
    "uni_ratio = sorted(gunma['該当比'].unique().tolist())\n",
    "colors = {1: '#ff0000', 2: '#ff8080', 3: '#ffffff', 4: '#8080ff', 5: '#0000ff'}\n",
    "labels = {1: '有意に高い', 2: '有意で無いが高い', 3: 'なし' ,4: '有意で無いが低い', 5: '有意に低い'}\n",
    "legend_colors = [colors[a] for a in uni_ratio]\n",
    "ratio_legend = [labels[a] for a in uni_ratio]\n",
    "cmaps = ListedColormap(legend_colors, name=\"custom\")\n",
    "########\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.axis('off')                      # 軸を表示しない\n",
    "gunma.plot(\n",
    "    ax = ax, \n",
    "    column = '該当比', \n",
    "    categorical = True,\n",
    "    cmap = cmaps,\n",
    "    edgecolor = '#000000', \n",
    "    linewidth = 1, \n",
    "    legend = True, \n",
    "    legend_kwds={'labels': ratio_legend}\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 完成版\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "from matplotlib.colors import ListedColormap \n",
    "import matplotlib\n",
    "\n",
    "# カラーを設定\n",
    "\n",
    "def colors_scale(legend_unique, cmap_name = 'bwr_r', division_number = 5):                  #色の分け方の定義\n",
    "    n_min = 1  #min(arr)\n",
    "    n_max = division_number   #max(arr)\n",
    "    cmap = plt.colormaps[cmap_name]\n",
    "    norm = matplotlib.colors.Normalize(vmin=n_min, vmax=n_max)\n",
    "    arr = [cmap(norm(r)) for r in legend_unique]\n",
    "    return arr, cmap, norm\n",
    "\n",
    "\n",
    "def plot_map_colors(df, facter_column = '区分'):                                            # マップの作製\n",
    "    legend_unique = sorted(df[facter_column].unique().tolist())\n",
    "    labels = {1: '有意に高い', 2: '有意で無いが高い', 3: 'なし' ,4: '有意で無いが低い', 5: '有意に低い'}\n",
    "    ratio_legend = [labels[a] for a in legend_unique]\n",
    "    target_colors, cmap, norm = colors_scale(legend_unique)\n",
    "    cmaps = ListedColormap(target_colors, name=\"custom\")\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.axis('off')                      # 軸を表示しない\n",
    "    df.plot(\n",
    "        ax = ax, \n",
    "        column = facter_column, \n",
    "        categorical = True,\n",
    "        cmap = cmaps,\n",
    "        edgecolor = '#000000', \n",
    "        linewidth = 1, \n",
    "        legend = True, \n",
    "        legend_kwds={'labels': ratio_legend}\n",
    "        )\n",
    "\n",
    "    # #ラベルを付ける\n",
    "    # for i, txt in enumerate(df['市町村名']):\n",
    "    #     ax.annotate(txt, (df.geometry[i].centroid.x, df.geometry[i].centroid.y),fontsize= 6,horizontalalignment='center', verticalalignment='center')\n",
    "    # fig.text(0.5, 0.1, '※本資料を活用するには、必ず、各市町村の表も合わせて解釈を行うこと。', ha='center',fontsize= 10, horizontalalignment=\"center\",verticalalignment=\"center\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "# テスト用のデータを作成\n",
    "municipalities = gunma['市町村名'].unique().tolist()\n",
    "lists = [random.choice([1, 2, 3, 4]) for i in range(len(gunma['市町村名'].unique()))]\n",
    "df_municipalities = pd.DataFrame({'市町村名': municipalities,\n",
    "                                  '該当比': lists})\n",
    "gunma = pd.merge(gunma, df_municipalities, on = '市町村名')\n",
    "\n",
    "plot_map_colors(gunma, facter_column = '該当比')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 任意の地域別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保健所機能(圏域)に変換 保健所区域\n",
    "def make_h_area(df):\n",
    "    town=[['渋川市','榛東村','吉岡町'], ['伊勢崎市','玉村町'], ['安中市'], ['藤岡市','上野村','神流町'], \n",
    "          ['富岡市','下仁田町','南牧村','甘楽町'], ['中之条町','長野原町','嬬恋村','草津町','高山村','東吾妻町'],\n",
    "          ['沼田市','片品村','川場村','昭和村','みなかみ町'], ['太田市'],['桐生市','みどり市'], \n",
    "          ['館林市','板倉町','明和町','千代田町','大泉町','邑楽町'], ['高崎市'], ['前橋市']]\n",
    "    health_area=['渋川','伊勢崎','安中','藤岡','富岡','吾妻','利根沼田','太田','桐生','館林','高崎','前橋']\n",
    "    for i,j in zip(town,health_area): #2つのリストを1つずつ呼び出す\n",
    "        for k in i:\n",
    "            df.loc[df['市町村名'] == k, '保健所区域'] = j\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = make_h_area(gunma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "gunma = make_h_area(gunma)\n",
    "municipalities = gunma['保健所区域'].unique().tolist()\n",
    "lists = [random.choice(['1', '2', '3', '4', '5']) for i in range(len(gunma['保健所区域'].unique()))]\n",
    "df_municipalities = pd.DataFrame({'保健所区域': municipalities,\n",
    "                                  '該当比': lists})\n",
    "gunma = pd.merge(gunma, df_municipalities, on = '保健所区域')\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.axis('off')                      # 軸を表示しない\n",
    "gunma.dissolve(by = '保健所区域').plot(\n",
    "    ax = ax, \n",
    "    column = '該当比', \n",
    "    cmap = 'bwr_r',\n",
    "    edgecolor = '#000000', \n",
    "    linewidth = 1, \n",
    "    legend = True, \n",
    "    #scheme = 'quantiles',\n",
    "    legend_kwds={'labels': ['有意に高い', '有意で無いが高い', 'なし' ,'有意で無いが低い', '有意に低い'] }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ポイントプロット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = '/Volumes/USBDISK/AHHDC/オープンデータ/P04-20_10_GML/P04-20_10.shp'\n",
    "#https://nlftp.mlit.go.jp/ksj/gml/datalist/KsjTmplt-P04-v3_0.html\n",
    "hospitals = gpd.read_file(hp, encoding=\"cp932\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 病院を地図上にプロット\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.axis('off')                      # 軸を表示しない\n",
    "gunma.plot(ax = ax, edgecolor = '#000000', linewidth = 0.5, color = '#ffffff')  # 市町村境界を描画\n",
    "hospitals[hospitals['P04_008'] >= 20].plot(\n",
    "    ax = ax, \n",
    "    column = 'P04_008',\n",
    "    cmap = 'summer_r', \n",
    "    edgecolor = '#000000', \n",
    "    linewidth = 0.5, \n",
    "    legend = True,\n",
    "    legend_kwds={'label': '病院数', \n",
    "                 'shrink': 0.7,\n",
    "                 }, \n",
    "    s = 20\n",
    "    )  # 市町村境界を描画"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 診療科を追加する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(hospitals[hospitals['P04_008'] >= 100]['geometry'].to_list()[0])\n",
    "hospitals['P04_004']\n",
    "departments = hospitals['P04_004'].fillna('登録なし', inplace = True).to_list()\n",
    "''.join(departments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "departments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospitals.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
