{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "メタボの分類\n",
    "データ変換\n",
    "回帰\n",
    "スコアの評価\n",
    "データ化\n",
    "\n",
    "関数化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install patsy\n",
    "# ! pip3 install statsmodels\n",
    "# ! pip3 install --upgrade pip\n",
    "# ! pip3 install pandas\n",
    "#import, def, path\n",
    "import pandas as pd\n",
    "import os\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def make_pair(target_list, span):#リストから指定の間隔をあけて二つを取り出す\n",
    "    pairs = [[target_list[i], target_list[i + span]] for i in range(len(target_list) - span)]\n",
    "    return pairs\n",
    "def marge_columns(df, columns):#カラムを追加する\n",
    "    mid = pd.DataFrame(index=df.index, columns=columns)\n",
    "    return pd.concat([df, mid], axis=1)\n",
    "def check_metS(df, metS_facter):#メタボ因子を数値化\n",
    "    metS_keys = list(metS_facter.keys())\n",
    "    metS_values = list(metS_facter.values())\n",
    "    df['check_腹囲'] = list(eval(f\"df['{metS_keys[0]}'] {metS_values[0]}\"))\n",
    "    df['check_血圧'] = list(eval(f\"df['{metS_keys[1]}'] {metS_values[1]}\"))\n",
    "    df['check_血糖'] = list(eval(f\"df['{metS_keys[2]}'] {metS_values[2]}\"))\n",
    "    df['check_脂肪'] = list(eval(f\"df['{metS_keys[3]}'] {metS_values[3]}\"))\n",
    "    return df\n",
    "def categorize_facters(df, categorize_facter):# カテゴリー変数を２値化、trueが１、true_valueはリスト\n",
    "    facters = list(categorize_facter.keys())\n",
    "    true_values = list(categorize_facter.values())\n",
    "    for i, true_value in enumerate(true_values):\n",
    "        k += f\"df['{facters[i]}'] == {true_value} |\"\n",
    "    df[f'categorize_{facters[i]}'] = list(eval(k[: -1]))\n",
    "    return df\n",
    "\n",
    "df_name = pd.read_csv('/Volumes/USBDISK/AHHDC/sort_pg/練習用保健データ.csv',  encoding = 'cp932')\n",
    "#main_df_path = os.path.join(os.getcwd(), f'{df_name}.csv')\n",
    "target_list = list(range(2015, 2021))\n",
    "span = 4\n",
    "pairs_column = '検診実施年度'\n",
    "metS_facter = {'腹囲':'>= 85', '血圧':'>= 130', '血糖':'>= 110', '脂肪':'>= 150'}\n",
    "metS_keys = list(metS_facter.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_name.copy()\n",
    "#df = df['空腹時血糖']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df = df_name.copy()\n",
    "metS_facter = [\n",
    "    ['性別', '腹囲'],               # 腹囲\n",
    "    ['収縮機血圧', '拡張期血圧'],     # 血圧\n",
    "    ['空腹時血糖', 'HbA1c'],        # 血糖\n",
    "    ['中性脂肪', 'HDL']             # 脂質\n",
    "]\n",
    "\n",
    "df['腹囲_'] = (((df[metS_facter[0][0]] == 1) & (df[metS_facter[0][1]] >= 85) |   # 男性\n",
    "              (df[metS_facter[0][0]] == 0) & (df[metS_facter[0][1]] >= 90))     # 女性\n",
    "               .where((df[metS_facter[0][0]].notnull()) & (df[metS_facter[0][1]].notnull()), np.nan)) \n",
    "df['血圧_'] = (((df[metS_facter[1][0]] >= 130) |    # 収縮期血圧\n",
    "              (df[metS_facter[1][1]] >= 85))       # 拡張期血圧\n",
    "               .where((df[metS_facter[1][0]].notnull()) & (df[metS_facter[1][1]].notnull()), np.nan))\n",
    "df['血糖_'] = (((df[metS_facter[2][0]] >= 110) |    # 空腹時血糖\n",
    "              (df[metS_facter[2][1]] >= 5.6))             # HbA1c\n",
    "               .where((df[metS_facter[2][0]].notnull()) & (df[metS_facter[2][1]].notnull()), np.nan))\n",
    "df['脂質_'] = (((df[metS_facter[3][0]] >= 150) |    # 中性脂肪\n",
    "              (df['HDL'] <= 40))               # HDL\n",
    "               .where((df[metS_facter[3][0]].notnull()) & (df[metS_facter[3][1]].notnull()), np.nan))\n",
    "# nanの変換\n",
    "# df['腹囲'] = df['腹囲'].where((~df['腹囲'].notnull()) | (~df['性別'].notnull()), np.nan)\n",
    "# df['血圧'] = df['血圧'].where((~df['収縮機血圧'].notnull()) | (~df['拡張期血圧'].notnull()), np.nan)\n",
    "# df['血糖'] = df['血糖'].where((~df['空腹時血糖'].notnull()) | (~df['HbA1c'].notnull()), np.nan)\n",
    "# df['脂質'] = df['脂質'].where((~df['中性脂肪'].notnull()) | (~df['HDL'].notnull()), np.nan)\n",
    "\n",
    "# 判定\n",
    "df['MetS'] = (df['腹囲_'] == True) & ((df['血圧_'] + df['血糖_'] + df['脂質_'] >= 2))\n",
    "\n",
    "df_metS = df[df['MetS'] == True]\n",
    "df_non_metS = df[df['MetS'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main\n",
    "df = df_name\n",
    "id_column = 'Unnamed: 0'\n",
    "categorize_facter = {'namae':[1,2]}\n",
    "\n",
    "pairs = make_pair(target_list, span, id_column, categorize_facter)\n",
    "for pair in pairs:\n",
    "    df1 = df.query(f'{pairs_column} == {pair[0]}')#train\n",
    "    df1 = check_metS(df1, metS_facter)\n",
    "    df1 = categorize_facters(df1, categorize_facter)\n",
    "    df2 = df.query(f'{pairs_column} == {pair[1]}')#test\n",
    "    df2 = check_metS(df2, metS_facter)\n",
    "    df2 = df2.filter(regex = f'^({id_column}| check_)', axis = 1)#testは必要のないもの以外drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_name\n",
    "#df = marge_columns(df, ['check_腹囲', 'check_血圧', 'check_血糖', 'check_脂肪'])\n",
    "metS_values = list(metS_facter.values())\n",
    "a = '検診実施年度'\n",
    "true_value = [2018, 2019]\n",
    "k = ''\n",
    "for i in true_value:\n",
    "    k += f\"(df['{a}'] == {i}) |\"\n",
    "\n",
    "df[f'check_{a}'] = list(eval(k[:-1]))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "各群にrisk_facter_name\n",
    "\n",
    "比べてchange\n",
    "変化した：１\n",
    "変化なし：０\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_name = '睡眠時間'\n",
    "\n",
    "\n",
    "X = df[[column_name]] # 説明変数\n",
    "Y = df['species'].map({'versicolor': 0, 'virginica': 1}) # versicolorをクラス0, virginicaをクラス1とする\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0) # 80%のデータを学習データに、20%を検証データにする\n",
    "\n",
    "lr = LogisticRegression() # ロジスティック回帰モデルのインスタンスを作成\n",
    "lr.fit(X_train, Y_train) # ロジスティック回帰モデルの重みを学習\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#main\n",
    "\n",
    "df = pd.read_csv(main_df_path)\n",
    "id_column = 'Unnamed: 0'\n",
    "categorize_facter = {'namae':[1,2]}\n",
    "facter_bp = '血圧'\n",
    "bp_threshold = '>= 135'\n",
    "columns_list = list(df.columns)\n",
    "pairs = make_pair(target_list, span, id_column, categorize_facter)\n",
    "for pair in pairs:\n",
    "    df1 = df.query(f'{pairs_column} == {pair[0]}')#train\n",
    "    df1['check_高血圧'] = list(eval(f\"df1['{facter_bp}'] {bp_threshold}\"))\n",
    "    df1 = df1[df1['check_高血圧'] == False]     #元々正常のみ\n",
    "\n",
    "    df2 = df.query(f'{pairs_column} == {pair[1]}')#test\n",
    "    df1['check_高血圧_after'] = list(eval(f\"df2['{facter_bp}'] {bp_threshold}\"))\n",
    "    df2 = df2.filter(regex = f'^({id_column}| check_)', axis = 1)#testは必要のないもの以外drop\n",
    "\n",
    "    df1.join(df2, on = id_column)\n",
    "    df1.dropna(subset=['check_高血圧_after'], inplace = True)\n",
    "    df1['bp_delta'] = df1['check_高血圧_after'] - df1['check_高血圧']\n",
    "\n",
    "    x = df1[['name']] # 説明変数\n",
    "    y = df1['bp_delta'].map({0: 0, 1: 1}) # falseをクラス0, Trueをクラス1とする\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size = 0.2, random_state = 0) # 80%のデータを学習データに、20%を検証データにする\n",
    "\n",
    "\n",
    "    lr = LogisticRegression() # ロジスティック回帰モデルのインスタンスを作成\n",
    "    lr.fit(X_train, Y_train) # ロジスティック回帰モデルの重みを学習\n",
    "\n",
    "\n",
    "    df_model[\"偏回帰係数\"] = model.coef_[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# データの読み込み\n",
    "exam_data = pd.read_csv(\"exam_data.csv\")\n",
    "# データのグラフ化\n",
    "\n",
    "\n",
    "# モデル化\n",
    "logistic_model = smf.glm(formula = \"result ~ hours\", # 目的変数~説明変数\n",
    "                       data = exam_data, \n",
    "                       family=sm.families.Binomial(link=sm.genmod.families.links.logit())\n",
    "                        )\n",
    "\n",
    "logistic_result = logistic_model.fit()\n",
    "\n",
    "logistic_result.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X2乗検定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "chi2, p, dof, exp = stats.chi2_contingency(df_name['検診実施年度','市町村名'], correction=False) #correction:イェーツの補正\n",
    "print(\"期待度数\", \"\\n\", exp)\n",
    "print(\"自由度\", \"\\n\", dof)\n",
    "print(\"カイ二乗値\", \"\\n\", chi2)\n",
    "print(\"p値\", \"\\n\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "def chi_squeretest(df, facters_list = []):\n",
    "    facters_pairs = [[facters_pair] for facters_pair in combinations(facters_list, 2)]\n",
    "    separate_facter = []\n",
    "    for facters_pair in facters_pairs:\n",
    "        chi2, p, dof, exp = stats.chi2_contingency(df[facters_pair], correction=False) #correction:イェーツの補正\n",
    "        if p < 0.05 :\n",
    "            separate_facter.append(facters_pair)\n",
    "    return separate_facter#[[a,a],[b,b]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "facters_list = ['検診実施年度', '市町村名']\n",
    "categorize_threshhold = 3\n",
    "df = df_name\n",
    "#X2検定\n",
    "from itertools import combinations\n",
    "def chi_squeretest(df, categorize_threshhold = 3, facters_list = []):\n",
    "    categorize_facters_list = [facter for facter in facters_list if len(df[facter].unique()) < categorize_threshhold]\n",
    "    facters_pairs = [facters_pair for facters_pair in combinations(categorize_facters_list, 2)]\n",
    "    separate_facter = []\n",
    "    print(facters_pairs)\n",
    "    for facters_pair in facters_pairs:\n",
    "        cross_tab = pd.crosstab(df[facters_pair[0]], df[facters_pair[1]])\n",
    "        print(cross_tab)\n",
    "        p = stats.chi2_contingency(cross_tab, correction=False)[1] #correction:イェーツの補正\n",
    "        print(p)\n",
    "        if p < 0.05 :\n",
    "            separate_facter.append(facters_pair)\n",
    "    return separate_facter#[[a,a],[b,b]]\n",
    "\n",
    "\n",
    "def fisher_exact_test(df, categorize_threshhold = 3, facters_list = []):\n",
    "    categorize_facters_list = [facter for facter in facters_list if len(df[facter].unique()) < categorize_threshhold]\n",
    "    facters_pairs = [facters_pair for facters_pair in combinations(categorize_facters_list, 2)]\n",
    "    separate_facter = []\n",
    "    for facters_pair in facters_pairs:\n",
    "        cross_tab = pd.crosstab(df[facters_pair[0]], df[facters_pair[1]])\n",
    "        p = stats.fisher_exact(cross_tab)[1] #correction:イェーツの補正\n",
    "        if p < 0.05 :\n",
    "            separate_facter.append(facters_pair)\n",
    "    return separate_facter#[[a,a],[b,b]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_tab = pd.crosstab(df[facters_list[0]], df[facters_list[1]])\n",
    "cross_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_sums = cross_tab.sum().to_list()        #c   \n",
    "row_sums = cross_tab.sum(axis = 1).to_list()   #r\n",
    "full_sum = sum(column_sums)                    #n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import itertools\n",
    "def list_factorial_sum(taraget_list):\n",
    "    sum = 0\n",
    "    for target in taraget_list:\n",
    "        m = math.factorial(target)\n",
    "        sum += m\n",
    "    return sum\n",
    "\n",
    "\n",
    "column_factorial = 0\n",
    "for column_sum in column_sums:\n",
    "    m = math.factorial(column_sum)\n",
    "    column_factorial += m\n",
    "\n",
    "row_factorial = 0\n",
    "for row_sum in row_sums:\n",
    "    m = math.factorial(row_sum)\n",
    "    row_factorial += m\n",
    "\n",
    "n_factorial = math.factorial(full_sum)\n",
    "\n",
    "values_factorial = 0\n",
    "cross_tab_values = list(itertools.chain.from_iterable(cross_tab.values.tolist()))\n",
    "for cross_tab_value in cross_tab_values:\n",
    "    m = math.factorial(cross_tab_value)\n",
    "    values_factorial += m\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_tab_values = cross_tab.values.tolist()\n",
    "for cross_tab_value in cross_tab_values:    #行ごと\n",
    "    rows_value_factorial_sum = 0\n",
    "    for i, cross_tab_value in enumerate(cross_tab_values):\n",
    "        row_value_factorial_sum = list_factorial_sum(cross_tab_value)\n",
    "        row_factorial = math.factorial(column_sums[i])\n",
    "        k = row_value_factorial_sum/row_factorial\n",
    "        rows_value_factorial_sum += k\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_value_factorial_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_p = n_factorial/column_factorial\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_p = n_factorial/column_factorial\n",
    "p\n",
    "rows_value_factorial_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_tab_values = cross_tab.values.tolist()\n",
    "for cross_tab_value in cross_tab_values:    #行ごと\n",
    "    rows_value_factorial_sum = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 綺麗なエクセルを整形する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "\n",
    "book = openpyxl.Workbook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['haba'] = f\"{df['random_num1']}\" + f\"{df['random_num2']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
